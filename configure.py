#!/usr/bin/env python3
"""
OpenBB Financial Agent Configuration Helper

This script helps you configure your LLM provider quickly.
"""

import os
import sys

def create_env_file(provider, api_key=None, ollama_model="gemma2:2b"):
    """Create .env file with the specified configuration"""
    
    env_content = f"""# OpenBB Financial Agent Configuration
# Generated by configure.py

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
LLM_PROVIDER={provider}

"""
    
    if provider == "openai":
        env_content += f"""# OpenAI Configuration
OPENAI_API_KEY={api_key or 'your_openai_api_key_here'}
OPENAI_MODEL=gpt-4o-mini

"""
    else:
        env_content += f"""# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL={ollama_model}

"""
    
    env_content += """# =============================================================================
# OPTIONAL SETTINGS
# =============================================================================
# OpenBB token for enhanced data access
# OPENBB_TOKEN=your_openbb_token_here

# Server configuration
SERVER_PORT=7777
CONNECTION_TIMEOUT=10.0
READ_TIMEOUT=30.0

# Email alerts (optional)
# EMAIL_FROM=noreply@example.com
# EMAIL_TO=admin@example.com
# SMTP_SERVER=smtp.gmail.com
# SMTP_USER=your_email@gmail.com
# SMTP_PASS=your_app_password
"""
    
    with open('.env', 'w') as f:
        f.write(env_content)
    
    print(f"‚úÖ Created .env file with {provider} configuration")

def main():
    print("ü§ñ OpenBB Financial Agent Configuration")
    print("=" * 50)
    
    while True:
        print("\nChoose your LLM provider:")
        print("1. OpenAI (Recommended - best quality, requires API key)")
        print("2. Ollama (Free - runs locally, requires Ollama installed)")
        print("3. Exit")
        
        choice = input("\nEnter your choice (1-3): ").strip()
        
        if choice == "1":
            print("\nüìù OpenAI Configuration")
            print("Get your API key from: https://platform.openai.com/api-keys")
            api_key = input("Enter your OpenAI API key (or press Enter to configure later): ").strip()
            
            create_env_file("openai", api_key)
            
            print("\nüöÄ Next steps:")
            print("1. Run: docker-compose up --build")
            print("2. Open: http://localhost:7777")
            break
            
        elif choice == "2":
            print("\nüè† Ollama Configuration")
            print("Make sure Ollama is installed and running:")
            print("1. Install from: https://ollama.ai")
            print("2. Start server: ollama serve")
            
            model = input("Enter Ollama model name [gemma2:2b]: ").strip() or "gemma2:2b"
            
            create_env_file("ollama", ollama_model=model)
            
            print("\nüöÄ Next steps:")
            print(f"1. Run: ollama serve")
            print(f"2. Run: ollama pull {model}")
            print("3. Run: docker-compose up --build")
            print("4. Open: http://localhost:7777")
            break
            
        elif choice == "3":
            print("üëã Goodbye!")
            sys.exit(0)
        else:
            print("‚ùå Invalid choice. Please enter 1, 2, or 3.")

if __name__ == "__main__":
    main() 